# ğŸ§ª æµ‹è¯•æŒ‡å—

> **MCP æœåŠ¡å™¨è„šæ‰‹æ¶çš„å…¨é¢æµ‹è¯•ç­–ç•¥ - ç¡®ä¿ä»£ç è´¨é‡å’ŒåŠŸèƒ½å¯é æ€§**

## ğŸ¯ æµ‹è¯•ç­–ç•¥æ¦‚è§ˆ

æœ¬æ–‡æ¡£æä¾› **Awesome-MCP-Scaffold** é¡¹ç›®çš„å®Œæ•´æµ‹è¯•æŒ‡å—ï¼Œæ¶µç›– MCP åè®®çš„ç‰¹æ®Šæµ‹è¯•éœ€æ±‚å’Œæœ€ä½³å®è·µã€‚ä½œä¸ºè„šæ‰‹æ¶é¡¹ç›®ï¼Œè¿™äº›æµ‹è¯•æ¨¡å¼å°†æŒ‡å¯¼åŸºäºæ­¤æ¨¡æ¿å¼€å‘çš„ MCP æœåŠ¡å™¨ã€‚

## ğŸ“Š æµ‹è¯•å±‚æ¬¡æ¶æ„

### æµ‹è¯•é‡‘å­—å¡”

```
    ğŸ”º E2E æµ‹è¯• (5%)
       â”œâ”€â”€ MCP å®¢æˆ·ç«¯é›†æˆæµ‹è¯•
       â””â”€â”€ å®Œæ•´å·¥ä½œæµéªŒè¯
    
    ğŸ”· é›†æˆæµ‹è¯• (25%)
       â”œâ”€â”€ HTTP API ç«¯ç‚¹æµ‹è¯•
       â”œâ”€â”€ MCP åè®®äº¤äº’æµ‹è¯•
       â””â”€â”€ æ•°æ®åº“/å¤–éƒ¨æœåŠ¡é›†æˆ
    
    ğŸ”¶ å•å…ƒæµ‹è¯• (70%)
       â”œâ”€â”€ Tools åŠŸèƒ½æµ‹è¯•
       â”œâ”€â”€ Resources é€»è¾‘æµ‹è¯•
       â”œâ”€â”€ Prompts æ¨¡æ¿æµ‹è¯•
       â””â”€â”€ å·¥å…·å‡½æ•°æµ‹è¯•
```

### æµ‹è¯•è¦†ç›–ç›®æ ‡

| ç»„ä»¶ç±»å‹ | è¦†ç›–ç‡ç›®æ ‡ | é‡ç‚¹æµ‹è¯•å†…å®¹ |
|----------|-----------|-------------|
| **MCP Tools** | 95%+ | åŠŸèƒ½æ­£ç¡®æ€§ã€è¾“å…¥éªŒè¯ã€é”™è¯¯å¤„ç† |
| **MCP Resources** | 90%+ | æ•°æ®è·å–ã€ç¼“å­˜æœºåˆ¶ã€æƒé™æ§åˆ¶ |
| **MCP Prompts** | 85%+ | æ¨¡æ¿æ¸²æŸ“ã€å‚æ•°éªŒè¯ã€è¾“å‡ºæ ¼å¼ |
| **HTTP Routes** | 90%+ | ç«¯ç‚¹å“åº”ã€çŠ¶æ€ç ã€æ•°æ®æ ¼å¼ |
| **é…ç½®ç®¡ç†** | 80%+ | ç¯å¢ƒå˜é‡ã€é»˜è®¤å€¼ã€éªŒè¯é€»è¾‘ |

## ğŸ› ï¸ æµ‹è¯•ç¯å¢ƒé…ç½®

### 1. æµ‹è¯•ä¾èµ–å®‰è£…

```bash
# å®‰è£…æµ‹è¯•ç›¸å…³ä¾èµ–
pip install pytest pytest-asyncio pytest-cov pytest-mock httpx
pip install faker factory-boy freezegun

# æˆ–ä½¿ç”¨é¡¹ç›®é…ç½®
pip install -e ".[dev]"
```

### 2. pytest é…ç½®

```toml
# pyproject.toml
[tool.pytest.ini_options]
minversion = "7.0"
addopts = [
    "-ra",
    "-q", 
    "--strict-markers",
    "--strict-config",
    "--cov=server",
    "--cov-report=html",
    "--cov-report=term-missing"
]
testpaths = ["tests"]
asyncio_mode = "auto"
markers = [
    "unit: å•å…ƒæµ‹è¯•",
    "integration: é›†æˆæµ‹è¯•", 
    "e2e: ç«¯åˆ°ç«¯æµ‹è¯•",
    "slow: æ…¢é€Ÿæµ‹è¯•",
    "external: éœ€è¦å¤–éƒ¨æœåŠ¡çš„æµ‹è¯•"
]
```

### 3. æµ‹è¯•ç¯å¢ƒéš”ç¦»

```python
# tests/conftest.py
"""
æµ‹è¯•é…ç½®å’Œ fixtures
"""

import pytest
import tempfile
import os
from pathlib import Path
from unittest.mock import Mock

from server.config import Settings


@pytest.fixture(scope="session", autouse=True)
def setup_test_environment():
    """è®¾ç½®æµ‹è¯•ç¯å¢ƒå˜é‡"""
    # åˆ›å»ºä¸´æ—¶æµ‹è¯•ç›®å½•
    test_dir = tempfile.mkdtemp()
    
    # è®¾ç½®æµ‹è¯•ç¯å¢ƒå˜é‡
    os.environ.update({
        "ENVIRONMENT": "testing",
        "LOG_LEVEL": "DEBUG",
        "TEST_DATA_DIR": test_dir,
        "DATABASE_URL": "sqlite:///test.db",
        "REDIS_URL": "redis://localhost:6379/1"
    })
    
    yield test_dir
    
    # æ¸…ç†
    import shutil
    shutil.rmtree(test_dir, ignore_errors=True)


@pytest.fixture
def test_settings():
    """æµ‹è¯•é…ç½® fixture"""
    return Settings(
        environment="testing",
        debug=True,
        log_level="DEBUG"
    )


@pytest.fixture
def workspace_dir():
    """å·¥ä½œç›®å½• fixture"""
    workspace = Path.cwd() / "workspace"
    workspace.mkdir(exist_ok=True)
    
    yield workspace
    
    # å¯é€‰ï¼šæ¸…ç†æµ‹è¯•æ–‡ä»¶
    # import shutil
    # shutil.rmtree(workspace, ignore_errors=True)


@pytest.fixture
def sample_json_data():
    """ç¤ºä¾‹ JSON æ•°æ®"""
    return {
        "name": "Test User",
        "email": "test@example.com",
        "age": 30,
        "skills": ["Python", "MCP", "Testing"]
    }


@pytest.fixture
def mock_external_api():
    """æ¨¡æ‹Ÿå¤–éƒ¨ API"""
    mock = Mock()
    mock.get.return_value.json.return_value = {"status": "success"}
    mock.get.return_value.status_code = 200
    return mock
```

## ğŸ”§ MCP Tools æµ‹è¯•

### 1. åŸºæœ¬å·¥å…·æµ‹è¯•

```python
# tests/test_tools.py
"""
MCP å·¥å…·æµ‹è¯•
"""

import pytest
from unittest.mock import patch, Mock
from server.tools.calculator import add, subtract, calculate_bmi
from server.tools.text_processing import count_words, extract_emails
from server.tools.file_operations import read_file, write_file


class TestCalculatorTools:
    """è®¡ç®—å™¨å·¥å…·æµ‹è¯•"""

    def test_add_positive_numbers(self):
        """æµ‹è¯•æ­£æ•°åŠ æ³•"""
        result = add(5, 3)
        assert result == 8

    def test_add_negative_numbers(self):
        """æµ‹è¯•è´Ÿæ•°åŠ æ³•"""
        result = add(-5, -3)
        assert result == -8

    def test_add_mixed_numbers(self):
        """æµ‹è¯•æ­£è´Ÿæ•°æ··åˆåŠ æ³•"""
        result = add(5, -3)
        assert result == 2

    def test_add_zero(self):
        """æµ‹è¯•é›¶å€¼åŠ æ³•"""
        result = add(0, 5)
        assert result == 5

    def test_add_float_precision(self):
        """æµ‹è¯•æµ®ç‚¹æ•°ç²¾åº¦"""
        result = add(0.1, 0.2)
        assert result == pytest.approx(0.3, rel=1e-9)

    def test_subtract_basic(self):
        """æµ‹è¯•åŸºæœ¬å‡æ³•"""
        result = subtract(10, 3)
        assert result == 7

    def test_divide_by_zero(self):
        """æµ‹è¯•é™¤é›¶é”™è¯¯"""
        from server.tools.calculator import divide
        
        with pytest.raises(ValueError, match="Cannot divide by zero"):
            divide(10, 0)

    def test_calculate_bmi_normal(self):
        """æµ‹è¯•æ­£å¸¸ BMI è®¡ç®—"""
        # 70kg, 1.75m -> BMI â‰ˆ 22.86
        result = calculate_bmi(70, 1.75)
        expected_bmi = 70 / (1.75 ** 2)
        
        assert result["bmi"] == pytest.approx(expected_bmi, rel=1e-2)
        assert result["category"] in ["æ­£å¸¸ä½“é‡", "Normal"]

    def test_calculate_bmi_invalid_weight(self):
        """æµ‹è¯•æ— æ•ˆä½“é‡"""
        with pytest.raises(ValueError, match="Weight must be positive"):
            calculate_bmi(-70, 1.75)

    def test_calculate_bmi_invalid_height(self):
        """æµ‹è¯•æ— æ•ˆèº«é«˜"""
        with pytest.raises(ValueError, match="Height must be positive"):
            calculate_bmi(70, 0)

    @pytest.mark.parametrize("weight,height,expected_category", [
        (45, 1.70, "åç˜¦"),
        (70, 1.75, "æ­£å¸¸"),
        (90, 1.75, "åèƒ–"),
        (110, 1.75, "è‚¥èƒ–")
    ])
    def test_bmi_categories(self, weight, height, expected_category):
        """æµ‹è¯• BMI åˆ†ç±»"""
        result = calculate_bmi(weight, height)
        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…å®ç°è°ƒæ•´æ–­è¨€
        assert "category" in result


class TestTextProcessingTools:
    """æ–‡æœ¬å¤„ç†å·¥å…·æµ‹è¯•"""

    def test_count_words_simple(self):
        """æµ‹è¯•ç®€å•å•è¯è®¡æ•°"""
        text = "Hello world this is a test"
        result = count_words(text)
        
        assert result["words"] == 6
        assert result["characters"] == 26
        assert result["lines"] == 1

    def test_count_words_empty(self):
        """æµ‹è¯•ç©ºæ–‡æœ¬"""
        result = count_words("")
        
        assert result["words"] == 0
        assert result["characters"] == 0

    def test_count_words_multiline(self):
        """æµ‹è¯•å¤šè¡Œæ–‡æœ¬"""
        text = "Line 1\nLine 2\nLine 3"
        result = count_words(text)
        
        assert result["lines"] == 3
        assert result["words"] == 6

    def test_extract_emails_single(self):
        """æµ‹è¯•æå–å•ä¸ªé‚®ç®±"""
        text = "Contact us at test@example.com for more info"
        result = extract_emails(text)
        
        assert result == ["test@example.com"]

    def test_extract_emails_multiple(self):
        """æµ‹è¯•æå–å¤šä¸ªé‚®ç®±"""
        text = "Email admin@test.org or support@company.com"
        result = extract_emails(text)
        
        assert len(result) == 2
        assert "admin@test.org" in result
        assert "support@company.com" in result

    def test_extract_emails_none(self):
        """æµ‹è¯•æ— é‚®ç®±æ–‡æœ¬"""
        text = "This text has no email addresses"
        result = extract_emails(text)
        
        assert result == []

    def test_extract_emails_invalid(self):
        """æµ‹è¯•æ— æ•ˆé‚®ç®±æ ¼å¼"""
        text = "Invalid emails: test@, @example.com, test.com"
        result = extract_emails(text)
        
        assert result == []

    @pytest.mark.parametrize("input_text,expected_slug", [
        ("Hello World", "hello-world"),
        ("Test with 123 Numbers!", "test-with-123-numbers"),
        ("Special@#$%Characters", "special-characters"),
        ("Multiple   Spaces", "multiple-spaces")
    ])
    def test_text_to_slug(self, input_text, expected_slug):
        """æµ‹è¯•æ–‡æœ¬è½¬ slug"""
        from server.tools.text_processing import text_to_slug
        result = text_to_slug(input_text)
        assert result == expected_slug


class TestFileOperationTools:
    """æ–‡ä»¶æ“ä½œå·¥å…·æµ‹è¯•"""

    def test_read_file_success(self, workspace_dir):
        """æµ‹è¯•æˆåŠŸè¯»å–æ–‡ä»¶"""
        # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        test_file = workspace_dir / "test.txt"
        test_content = "This is test content"
        test_file.write_text(test_content)
        
        # æµ‹è¯•è¯»å–
        result = read_file("test.txt")
        assert result == test_content

    def test_read_file_not_found(self):
        """æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨"""
        with pytest.raises(FileNotFoundError):
            read_file("nonexistent.txt")

    def test_read_file_path_traversal(self):
        """æµ‹è¯•è·¯å¾„éå†æ”»å‡»"""
        with pytest.raises(ValueError, match="Path is outside workspace"):
            read_file("../../../etc/passwd")

    def test_write_file_success(self, workspace_dir):
        """æµ‹è¯•æˆåŠŸå†™å…¥æ–‡ä»¶"""
        content = "New file content"
        result = write_file("new_file.txt", content)
        
        assert result["success"] is True
        
        # éªŒè¯æ–‡ä»¶å†…å®¹
        written_file = workspace_dir / "new_file.txt"
        assert written_file.exists()
        assert written_file.read_text() == content

    def test_write_file_overwrite(self, workspace_dir):
        """æµ‹è¯•è¦†ç›–ç°æœ‰æ–‡ä»¶"""
        filename = "overwrite_test.txt"
        original_content = "Original content"
        new_content = "New content"
        
        # åˆ›å»ºåŸå§‹æ–‡ä»¶
        write_file(filename, original_content)
        
        # è¦†ç›–æ–‡ä»¶
        result = write_file(filename, new_content)
        
        assert result["success"] is True
        
        # éªŒè¯å†…å®¹å·²æ›´æ–°
        test_file = workspace_dir / filename
        assert test_file.read_text() == new_content

    def test_json_operations(self, workspace_dir, sample_json_data):
        """æµ‹è¯• JSON æ–‡ä»¶æ“ä½œ"""
        from server.tools.file_operations import write_json_file, read_json_file
        
        filename = "test_data.json"
        
        # å†™å…¥ JSON
        write_result = write_json_file(filename, sample_json_data)
        assert write_result["success"] is True
        
        # è¯»å– JSON
        read_result = read_json_file(filename)
        assert read_result == sample_json_data

    def test_list_directory(self, workspace_dir):
        """æµ‹è¯•ç›®å½•åˆ—è¡¨"""
        from server.tools.file_operations import list_directory
        
        # åˆ›å»ºæµ‹è¯•æ–‡ä»¶å’Œç›®å½•
        (workspace_dir / "file1.txt").write_text("content1")
        (workspace_dir / "file2.txt").write_text("content2")
        (workspace_dir / "subdir").mkdir()
        
        result = list_directory(".")
        
        assert "file1.txt" in result["files"]
        assert "file2.txt" in result["files"]
        assert "subdir" in result["directories"]
```

### 2. å¼‚æ­¥å·¥å…·æµ‹è¯•

```python
class TestAsyncTools:
    """å¼‚æ­¥å·¥å…·æµ‹è¯•"""

    @pytest.mark.asyncio
    async def test_async_api_call(self, mock_external_api):
        """æµ‹è¯•å¼‚æ­¥ API è°ƒç”¨å·¥å…·"""
        from server.tools.api_client import fetch_data
        
        with patch('httpx.AsyncClient') as mock_client:
            mock_client.return_value.__aenter__.return_value.get.return_value.json.return_value = {
                "data": "test response"
            }
            
            result = await fetch_data("https://api.example.com/data")
            
            assert result["data"] == "test response"

    @pytest.mark.asyncio
    async def test_async_timeout(self):
        """æµ‹è¯•å¼‚æ­¥è¶…æ—¶å¤„ç†"""
        import asyncio
        from server.tools.api_client import fetch_data_with_timeout
        
        with patch('httpx.AsyncClient') as mock_client:
            # æ¨¡æ‹Ÿè¶…æ—¶
            mock_client.return_value.__aenter__.return_value.get.side_effect = asyncio.TimeoutError()
            
            with pytest.raises(RuntimeError, match="Request timeout"):
                await fetch_data_with_timeout("https://slow-api.com", timeout=1)
```

## ğŸ“¡ MCP Resources æµ‹è¯•

```python
# tests/test_resources.py
"""
MCP èµ„æºæµ‹è¯•
"""

import pytest
from unittest.mock import patch, Mock
from server.resources.system_info import get_system_info
from server.resources.config_data import get_config_data


class TestSystemInfoResource:
    """ç³»ç»Ÿä¿¡æ¯èµ„æºæµ‹è¯•"""

    @patch('psutil.cpu_percent')
    @patch('psutil.virtual_memory')
    def test_get_cpu_memory_info(self, mock_memory, mock_cpu):
        """æµ‹è¯• CPU å’Œå†…å­˜ä¿¡æ¯è·å–"""
        # æ¨¡æ‹Ÿç³»ç»Ÿæ•°æ®
        mock_cpu.return_value = 45.5
        mock_memory.return_value = Mock(
            total=8589934592,  # 8GB
            available=4294967296,  # 4GB
            percent=50.0
        )
        
        result = get_system_info("cpu_memory")
        
        assert result["cpu_percent"] == 45.5
        assert result["memory_total"] == 8589934592
        assert result["memory_available"] == 4294967296
        assert result["memory_percent"] == 50.0

    @patch('psutil.disk_usage')
    def test_get_disk_info(self, mock_disk):
        """æµ‹è¯•ç£ç›˜ä¿¡æ¯è·å–"""
        mock_disk.return_value = Mock(
            total=1000000000000,  # 1TB
            used=500000000000,    # 500GB
            free=500000000000     # 500GB
        )
        
        result = get_system_info("disk")
        
        assert result["disk_total"] == 1000000000000
        assert result["disk_used"] == 500000000000
        assert result["disk_free"] == 500000000000

    def test_get_invalid_resource(self):
        """æµ‹è¯•æ— æ•ˆèµ„æºè¯·æ±‚"""
        with pytest.raises(ValueError, match="Unknown resource type"):
            get_system_info("invalid_resource")

    @patch('server.resources.system_info.cache')
    def test_resource_caching(self, mock_cache):
        """æµ‹è¯•èµ„æºç¼“å­˜æœºåˆ¶"""
        # æ¨¡æ‹Ÿç¼“å­˜å‘½ä¸­
        cached_data = {"cpu_percent": 30.0, "cached": True}
        mock_cache.get.return_value = cached_data
        
        result = get_system_info("cpu_memory")
        
        assert result == cached_data
        mock_cache.get.assert_called_once()


class TestConfigDataResource:
    """é…ç½®æ•°æ®èµ„æºæµ‹è¯•"""

    def test_get_app_config(self, test_settings):
        """æµ‹è¯•åº”ç”¨é…ç½®è·å–"""
        result = get_config_data("app_config")
        
        assert "app_name" in result
        assert "version" in result
        assert "environment" in result

    def test_get_user_config(self):
        """æµ‹è¯•ç”¨æˆ·é…ç½®è·å–"""
        with patch('server.resources.config_data.load_user_config') as mock_load:
            mock_load.return_value = {
                "theme": "dark",
                "language": "zh-CN",
                "notifications": True
            }
            
            result = get_config_data("user_config")
            
            assert result["theme"] == "dark"
            assert result["language"] == "zh-CN"
            assert result["notifications"] is True

    def test_config_validation(self):
        """æµ‹è¯•é…ç½®éªŒè¯"""
        from server.resources.config_data import validate_config
        
        valid_config = {
            "app_name": "Test App",
            "version": "1.0.0",
            "debug": False
        }
        
        # åº”è¯¥ä¸æŠ›å‡ºå¼‚å¸¸
        validate_config(valid_config)
        
        # æµ‹è¯•æ— æ•ˆé…ç½®
        invalid_config = {
            "app_name": "",  # ç©ºåç§°
            "version": "invalid-version"  # æ— æ•ˆç‰ˆæœ¬æ ¼å¼
        }
        
        with pytest.raises(ValueError):
            validate_config(invalid_config)
```

## ğŸ’¬ MCP Prompts æµ‹è¯•

```python
# tests/test_prompts.py
"""
MCP æç¤ºæµ‹è¯•
"""

import pytest
from server.prompts.code_review import generate_code_review_prompt
from server.prompts.data_analysis import generate_data_analysis_prompt


class TestCodeReviewPrompts:
    """ä»£ç å®¡æŸ¥æç¤ºæµ‹è¯•"""

    def test_code_review_basic(self):
        """æµ‹è¯•åŸºæœ¬ä»£ç å®¡æŸ¥æç¤º"""
        context = {
            "code": "def hello():\n    print('Hello, World!')",
            "language": "python",
            "focus": "general"
        }
        
        prompt = generate_code_review_prompt(context)
        
        assert "ä»£ç å®¡æŸ¥" in prompt
        assert "python" in prompt.lower()
        assert "def hello" in prompt

    def test_code_review_security_focus(self):
        """æµ‹è¯•å®‰å…¨æ€§å®¡æŸ¥æç¤º"""
        context = {
            "code": "import os\nos.system(user_input)",
            "language": "python",
            "focus": "security"
        }
        
        prompt = generate_code_review_prompt(context)
        
        assert "å®‰å…¨" in prompt
        assert "os.system" in prompt

    def test_code_review_missing_context(self):
        """æµ‹è¯•ç¼ºå°‘å¿…éœ€ä¸Šä¸‹æ–‡"""
        context = {
            "language": "python"
            # ç¼ºå°‘ "code" å­—æ®µ
        }
        
        with pytest.raises(ValueError, match="Missing required context"):
            generate_code_review_prompt(context)

    @pytest.mark.parametrize("language,expected_keywords", [
        ("python", ["PEP 8", "ç±»å‹æç¤º"]),
        ("javascript", ["ESLint", "å¼‚æ­¥"]),
        ("java", ["å‘½åè§„èŒƒ", "å¼‚å¸¸å¤„ç†"])
    ])
    def test_language_specific_prompts(self, language, expected_keywords):
        """æµ‹è¯•è¯­è¨€ç‰¹å®šçš„æç¤ºå†…å®¹"""
        context = {
            "code": "// Sample code",
            "language": language,
            "focus": "general"
        }
        
        prompt = generate_code_review_prompt(context)
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«è¯­è¨€ç‰¹å®šçš„å…³é”®è¯
        for keyword in expected_keywords:
            assert keyword in prompt


class TestDataAnalysisPrompts:
    """æ•°æ®åˆ†ææç¤ºæµ‹è¯•"""

    def test_statistical_analysis_prompt(self):
        """æµ‹è¯•ç»Ÿè®¡åˆ†ææç¤º"""
        context = {
            "data_type": "numerical",
            "analysis_type": "statistical",
            "columns": ["age", "income", "score"],
            "sample_size": 1000
        }
        
        prompt = generate_data_analysis_prompt(context)
        
        assert "ç»Ÿè®¡åˆ†æ" in prompt
        assert "age" in prompt
        assert "income" in prompt
        assert "1000" in prompt

    def test_prediction_model_prompt(self):
        """æµ‹è¯•é¢„æµ‹æ¨¡å‹æç¤º"""
        context = {
            "data_type": "mixed",
            "analysis_type": "prediction",
            "target_variable": "sales",
            "features": ["price", "marketing_budget", "season"]
        }
        
        prompt = generate_data_analysis_prompt(context)
        
        assert "é¢„æµ‹" in prompt
        assert "sales" in prompt
        assert "ç‰¹å¾" in prompt

    def test_prompt_length_limit(self):
        """æµ‹è¯•æç¤ºé•¿åº¦é™åˆ¶"""
        context = {
            "data_type": "text",
            "analysis_type": "sentiment",
            "description": "x" * 10000  # è¶…é•¿æè¿°
        }
        
        prompt = generate_data_analysis_prompt(context)
        
        # ç¡®ä¿æç¤ºä¸ä¼šè¿‡é•¿
        assert len(prompt) < 8000

    def test_invalid_analysis_type(self):
        """æµ‹è¯•æ— æ•ˆåˆ†æç±»å‹"""
        context = {
            "data_type": "numerical",
            "analysis_type": "invalid_type"
        }
        
        with pytest.raises(ValueError, match="Unsupported analysis type"):
            generate_data_analysis_prompt(context)
```

## ğŸŒ HTTP API é›†æˆæµ‹è¯•

```python
# tests/test_integration.py
"""
é›†æˆæµ‹è¯•
"""

import pytest
import httpx
from fastapi.testclient import TestClient
from server.main import create_app


@pytest.fixture
def test_client():
    """æµ‹è¯•å®¢æˆ·ç«¯ fixture"""
    app = create_app()
    return TestClient(app)


@pytest.fixture
def async_client():
    """å¼‚æ­¥æµ‹è¯•å®¢æˆ·ç«¯ fixture"""
    app = create_app()
    return httpx.AsyncClient(app=app, base_url="http://test")


class TestHealthEndpoints:
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹æµ‹è¯•"""

    def test_health_check(self, test_client):
        """æµ‹è¯•å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
        response = test_client.get("/health")
        
        assert response.status_code == 200
        data = response.json()
        assert data["status"] == "healthy"
        assert "timestamp" in data

    def test_info_endpoint(self, test_client):
        """æµ‹è¯•ä¿¡æ¯ç«¯ç‚¹"""
        response = test_client.get("/info")
        
        assert response.status_code == 200
        data = response.json()
        assert "app_name" in data
        assert "version" in data
        assert "environment" in data


class TestMCPAPIEndpoints:
    """MCP API ç«¯ç‚¹æµ‹è¯•"""

    def test_tools_list(self, test_client):
        """æµ‹è¯•å·¥å…·åˆ—è¡¨ç«¯ç‚¹"""
        response = test_client.get("/api/tools")
        
        assert response.status_code == 200
        data = response.json()
        assert isinstance(data, list)
        assert len(data) > 0
        
        # æ£€æŸ¥å·¥å…·ç»“æ„
        tool = data[0]
        assert "name" in tool
        assert "description" in tool

    def test_resources_list(self, test_client):
        """æµ‹è¯•èµ„æºåˆ—è¡¨ç«¯ç‚¹"""
        response = test_client.get("/api/resources")
        
        assert response.status_code == 200
        data = response.json()
        assert isinstance(data, list)

    def test_convert_text(self, test_client):
        """æµ‹è¯•æ–‡æœ¬è½¬æ¢ç«¯ç‚¹"""
        payload = {
            "text": "Hello World",
            "operation": "uppercase"
        }
        
        response = test_client.post("/api/convert", json=payload)
        
        assert response.status_code == 200
        data = response.json()
        assert data["result"] == "HELLO WORLD"

    def test_convert_invalid_operation(self, test_client):
        """æµ‹è¯•æ— æ•ˆè½¬æ¢æ“ä½œ"""
        payload = {
            "text": "Hello World",
            "operation": "invalid_op"
        }
        
        response = test_client.post("/api/convert", json=payload)
        
        assert response.status_code == 400


class TestMCPProtocolIntegration:
    """MCP åè®®é›†æˆæµ‹è¯•"""

    @pytest.mark.asyncio
    async def test_mcp_tools_list(self, async_client):
        """æµ‹è¯• MCP å·¥å…·åˆ—è¡¨"""
        mcp_request = {
            "jsonrpc": "2.0",
            "id": 1,
            "method": "tools/list"
        }
        
        response = await async_client.post("/mcp", json=mcp_request)
        
        assert response.status_code == 200
        data = response.json()
        assert data["jsonrpc"] == "2.0"
        assert "result" in data
        assert "tools" in data["result"]

    @pytest.mark.asyncio
    async def test_mcp_tool_call(self, async_client):
        """æµ‹è¯• MCP å·¥å…·è°ƒç”¨"""
        mcp_request = {
            "jsonrpc": "2.0",
            "id": 2,
            "method": "tools/call",
            "params": {
                "name": "add",
                "arguments": {
                    "a": 5,
                    "b": 3
                }
            }
        }
        
        response = await async_client.post("/mcp", json=mcp_request)
        
        assert response.status_code == 200
        data = response.json()
        assert data["result"]["content"][0]["text"] == "8"

    @pytest.mark.asyncio
    async def test_mcp_resources_list(self, async_client):
        """æµ‹è¯• MCP èµ„æºåˆ—è¡¨"""
        mcp_request = {
            "jsonrpc": "2.0",
            "id": 3,
            "method": "resources/list"
        }
        
        response = await async_client.post("/mcp", json=mcp_request)
        
        assert response.status_code == 200
        data = response.json()
        assert "result" in data
        assert "resources" in data["result"]

    @pytest.mark.asyncio
    async def test_mcp_resource_read(self, async_client):
        """æµ‹è¯• MCP èµ„æºè¯»å–"""
        mcp_request = {
            "jsonrpc": "2.0",
            "id": 4,
            "method": "resources/read",
            "params": {
                "uri": "system://cpu"
            }
        }
        
        response = await async_client.post("/mcp", json=mcp_request)
        
        assert response.status_code == 200
        data = response.json()
        assert "result" in data
        assert "contents" in data["result"]

    @pytest.mark.asyncio
    async def test_mcp_invalid_method(self, async_client):
        """æµ‹è¯•æ— æ•ˆ MCP æ–¹æ³•"""
        mcp_request = {
            "jsonrpc": "2.0",
            "id": 5,
            "method": "invalid/method"
        }
        
        response = await async_client.post("/mcp", json=mcp_request)
        
        assert response.status_code == 200
        data = response.json()
        assert "error" in data
        assert data["error"]["code"] == -32601  # Method not found
```

## ğŸ­ æ¨¡æ‹Ÿå’Œ Fixtures

### 1. å¤–éƒ¨æœåŠ¡æ¨¡æ‹Ÿ

```python
# tests/mocks.py
"""
æµ‹è¯•æ¨¡æ‹Ÿå·¥å…·
"""

from unittest.mock import Mock, AsyncMock
import pytest


class MockHTTPClient:
    """æ¨¡æ‹Ÿ HTTP å®¢æˆ·ç«¯"""
    
    def __init__(self, responses=None):
        self.responses = responses or {}
        self.call_count = 0
    
    async def get(self, url, **kwargs):
        self.call_count += 1
        
        if url in self.responses:
            response = Mock()
            response.json.return_value = self.responses[url]
            response.status_code = 200
            return response
        
        # é»˜è®¤å“åº”
        response = Mock()
        response.json.return_value = {"status": "ok"}
        response.status_code = 200
        return response


@pytest.fixture
def mock_weather_api():
    """æ¨¡æ‹Ÿå¤©æ°” API"""
    responses = {
        "https://api.weather.com/current": {
            "temperature": 25,
            "humidity": 60,
            "description": "Sunny"
        }
    }
    return MockHTTPClient(responses)


@pytest.fixture
def mock_database():
    """æ¨¡æ‹Ÿæ•°æ®åº“"""
    db = Mock()
    db.users = []
    
    def add_user(user):
        db.users.append(user)
        return len(db.users)
    
    def get_user(user_id):
        if 0 <= user_id < len(db.users):
            return db.users[user_id]
        return None
    
    db.add_user = add_user
    db.get_user = get_user
    
    return db
```

### 2. æ•°æ®ç”Ÿæˆå™¨

```python
# tests/factories.py
"""
æµ‹è¯•æ•°æ®å·¥å‚
"""

import factory
from faker import Faker
from datetime import datetime

fake = Faker()


class UserFactory(factory.Factory):
    """ç”¨æˆ·æ•°æ®å·¥å‚"""
    
    class Meta:
        model = dict
    
    id = factory.Sequence(lambda n: n)
    name = factory.LazyFunction(fake.name)
    email = factory.LazyFunction(fake.email)
    age = factory.LazyFunction(lambda: fake.random_int(18, 80))
    created_at = factory.LazyFunction(datetime.now)


class DocumentFactory(factory.Factory):
    """æ–‡æ¡£æ•°æ®å·¥å‚"""
    
    class Meta:
        model = dict
    
    title = factory.LazyFunction(fake.sentence)
    content = factory.LazyFunction(fake.text)
    author = factory.SubFactory(UserFactory)
    tags = factory.LazyFunction(lambda: fake.words(3))


# ä½¿ç”¨ç¤ºä¾‹
@pytest.fixture
def sample_users():
    """ç”Ÿæˆç¤ºä¾‹ç”¨æˆ·æ•°æ®"""
    return UserFactory.build_batch(5)


@pytest.fixture
def sample_document():
    """ç”Ÿæˆç¤ºä¾‹æ–‡æ¡£æ•°æ®"""
    return DocumentFactory.build()
```

## ğŸ“Š æ€§èƒ½æµ‹è¯•

```python
# tests/test_performance.py
"""
æ€§èƒ½æµ‹è¯•
"""

import pytest
import time
import asyncio
from concurrent.futures import ThreadPoolExecutor, as_completed


class TestPerformance:
    """æ€§èƒ½æµ‹è¯•ç±»"""

    def test_tool_execution_time(self):
        """æµ‹è¯•å·¥å…·æ‰§è¡Œæ—¶é—´"""
        from server.tools.calculator import calculate_bmi
        
        start_time = time.time()
        
        # æ‰§è¡Œå¤šæ¬¡æµ‹è¯•
        for _ in range(100):
            calculate_bmi(70, 1.75)
        
        end_time = time.time()
        avg_time = (end_time - start_time) / 100
        
        # æ–­è¨€å¹³å‡æ‰§è¡Œæ—¶é—´å°äº 1ms
        assert avg_time < 0.001

    @pytest.mark.slow
    def test_concurrent_tool_calls(self):
        """æµ‹è¯•å¹¶å‘å·¥å…·è°ƒç”¨"""
        from server.tools.text_processing import count_words
        
        text = "This is a test text for concurrent processing"
        
        def call_tool():
            return count_words(text)
        
        start_time = time.time()
        
        # å¹¶å‘æ‰§è¡Œ
        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = [executor.submit(call_tool) for _ in range(100)]
            results = [future.result() for future in as_completed(futures)]
        
        end_time = time.time()
        
        # éªŒè¯æ‰€æœ‰ç»“æœä¸€è‡´
        assert all(r["words"] == results[0]["words"] for r in results)
        
        # éªŒè¯å¹¶å‘æ‰§è¡Œæ—¶é—´åˆç†
        assert end_time - start_time < 5.0

    @pytest.mark.asyncio
    async def test_async_performance(self):
        """æµ‹è¯•å¼‚æ­¥æ€§èƒ½"""
        from server.tools.api_client import fetch_data
        
        async def mock_fetch():
            await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
            return {"data": "test"}
        
        start_time = time.time()
        
        # å¹¶å‘æ‰§è¡Œå¼‚æ­¥ä»»åŠ¡
        tasks = [mock_fetch() for _ in range(10)]
        results = await asyncio.gather(*tasks)
        
        end_time = time.time()
        
        # éªŒè¯å¹¶å‘æ‰§è¡Œæ¯”ä¸²è¡Œå¿«
        assert end_time - start_time < 0.5  # åº”è¯¥æ¥è¿‘ 0.1 ç§’è€Œä¸æ˜¯ 1 ç§’
        assert len(results) == 10

    def test_memory_usage(self):
        """æµ‹è¯•å†…å­˜ä½¿ç”¨"""
        import psutil
        import os
        
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss
        
        # æ‰§è¡Œä¸€äº›æ“ä½œ
        from server.tools.file_operations import read_file, write_file
        
        for i in range(100):
            content = f"Test content {i}" * 100
            write_file(f"temp_{i}.txt", content)
            read_file(f"temp_{i}.txt")
        
        final_memory = process.memory_info().rss
        memory_increase = final_memory - initial_memory
        
        # å†…å­˜å¢é•¿åº”è¯¥åœ¨åˆç†èŒƒå›´å†…ï¼ˆå°äº 50MBï¼‰
        assert memory_increase < 50 * 1024 * 1024
```

## ğŸš€ CI/CD æµ‹è¯•é…ç½®

### 1. GitHub Actions é…ç½®

```yaml
# .github/workflows/test.yml
name: Test Suite

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.10, 3.11, 3.12]

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v3
      with:
        python-version: ${{ matrix.python-version }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"

    - name: Run unit tests
      run: |
        pytest tests/test_tools.py tests/test_resources.py tests/test_prompts.py -v

    - name: Run integration tests
      run: |
        pytest tests/test_integration.py -v

    - name: Run performance tests
      run: |
        pytest tests/test_performance.py -v -m "not slow"

    - name: Generate coverage report
      run: |
        pytest --cov=server --cov-report=xml

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
```

### 2. æµ‹è¯•æ•°æ®ç®¡ç†

```python
# tests/test_data.py
"""
æµ‹è¯•æ•°æ®ç®¡ç†
"""

import json
from pathlib import Path


class TestDataManager:
    """æµ‹è¯•æ•°æ®ç®¡ç†å™¨"""
    
    def __init__(self, data_dir: Path = None):
        self.data_dir = data_dir or Path(__file__).parent / "data"
        self.data_dir.mkdir(exist_ok=True)
    
    def load_json(self, filename: str) -> dict:
        """åŠ è½½ JSON æµ‹è¯•æ•°æ®"""
        file_path = self.data_dir / filename
        if not file_path.exists():
            raise FileNotFoundError(f"Test data file not found: {filename}")
        
        with file_path.open('r', encoding='utf-8') as f:
            return json.load(f)
    
    def save_json(self, filename: str, data: dict) -> None:
        """ä¿å­˜ JSON æµ‹è¯•æ•°æ®"""
        file_path = self.data_dir / filename
        with file_path.open('w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)


@pytest.fixture
def test_data_manager():
    """æµ‹è¯•æ•°æ®ç®¡ç†å™¨ fixture"""
    return TestDataManager()


# ä½¿ç”¨ç¤ºä¾‹
def test_with_json_data(test_data_manager):
    """ä½¿ç”¨ JSON æµ‹è¯•æ•°æ®çš„æµ‹è¯•"""
    user_data = test_data_manager.load_json("sample_users.json")
    
    # ä½¿ç”¨æµ‹è¯•æ•°æ®è¿›è¡Œæµ‹è¯•
    assert len(user_data) > 0
    assert "name" in user_data[0]
```

## ğŸ“‹ æµ‹è¯•æœ€ä½³å®è·µ

### 1. æµ‹è¯•ç»„ç»‡åŸåˆ™

- **AAA æ¨¡å¼**: Arrangeï¼ˆå‡†å¤‡ï¼‰ã€Actï¼ˆæ‰§è¡Œï¼‰ã€Assertï¼ˆæ–­è¨€ï¼‰
- **å•ä¸€èŒè´£**: æ¯ä¸ªæµ‹è¯•åªéªŒè¯ä¸€ä¸ªåŠŸèƒ½ç‚¹
- **ç‹¬ç«‹æ€§**: æµ‹è¯•ä¹‹é—´ä¸åº”æœ‰ä¾èµ–å…³ç³»
- **å¯é‡å¤æ€§**: æµ‹è¯•ç»“æœåº”è¯¥ä¸€è‡´å’Œå¯é¢„æµ‹

### 2. æµ‹è¯•å‘½åè§„èŒƒ

```python
# âœ… å¥½çš„æµ‹è¯•å‘½å
def test_calculate_bmi_with_valid_input_returns_correct_result():
    pass

def test_read_file_with_nonexistent_file_raises_file_not_found():
    pass

def test_extract_emails_from_text_with_multiple_emails_returns_all():
    pass

# âŒ ä¸å¥½çš„æµ‹è¯•å‘½å
def test_bmi():
    pass

def test_file():
    pass

def test_email():
    pass
```

### 3. æ–­è¨€æœ€ä½³å®è·µ

```python
# âœ… å…·ä½“çš„æ–­è¨€
assert result["status"] == "success"
assert len(emails) == 2
assert "error" not in response

# âœ… ä½¿ç”¨ pytest çš„ä¸“ç”¨æ–­è¨€
assert result == pytest.approx(22.86, rel=1e-2)
assert "test@example.com" in emails

# âœ… å¼‚å¸¸æ–­è¨€
with pytest.raises(ValueError, match="Weight must be positive"):
    calculate_bmi(-70, 1.75)

# âŒ æ¨¡ç³Šçš„æ–­è¨€
assert result
assert emails
assert response
```

### 4. æµ‹è¯•æ•°æ®ç®¡ç†

```python
# âœ… ä½¿ç”¨ fixtures ç®¡ç†æµ‹è¯•æ•°æ®
@pytest.fixture
def sample_user():
    return {
        "name": "Test User",
        "email": "test@example.com",
        "age": 30
    }

# âœ… å‚æ•°åŒ–æµ‹è¯•
@pytest.mark.parametrize("weight,height,expected", [
    (70, 1.75, 22.86),
    (60, 1.60, 23.44),
    (80, 1.80, 24.69)
])
def test_bmi_calculation(weight, height, expected):
    result = calculate_bmi(weight, height)
    assert result["bmi"] == pytest.approx(expected, rel=1e-2)
```

## ğŸ” è°ƒè¯•å’Œæ•…éšœæ’é™¤

### 1. æµ‹è¯•è°ƒè¯•æŠ€å·§

```python
# ä½¿ç”¨ pytest çš„è°ƒè¯•åŠŸèƒ½
pytest -v -s  # æ˜¾ç¤ºè¯¦ç»†è¾“å‡º
pytest --pdb  # å¤±è´¥æ—¶è¿›å…¥è°ƒè¯•å™¨
pytest -k "test_name"  # è¿è¡Œç‰¹å®šæµ‹è¯•

# åœ¨æµ‹è¯•ä¸­æ·»åŠ è°ƒè¯•ä¿¡æ¯
def test_complex_logic():
    result = complex_function(input_data)
    
    # è°ƒè¯•è¾“å‡º
    print(f"Input: {input_data}")
    print(f"Result: {result}")
    
    assert result.is_valid()
```

### 2. å¸¸è§é—®é¢˜è§£å†³

```python
# é—®é¢˜ï¼šå¼‚æ­¥æµ‹è¯•å¤±è´¥
# è§£å†³ï¼šç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„å¼‚æ­¥æ ‡è®°
@pytest.mark.asyncio
async def test_async_function():
    result = await async_function()
    assert result is not None

# é—®é¢˜ï¼šæ–‡ä»¶è·¯å¾„é—®é¢˜
# è§£å†³ï¼šä½¿ç”¨ç›¸å¯¹äºæµ‹è¯•æ–‡ä»¶çš„è·¯å¾„
test_file = Path(__file__).parent / "data" / "test.txt"

# é—®é¢˜ï¼šæ—¶é—´ç›¸å…³æµ‹è¯•ä¸ç¨³å®š
# è§£å†³ï¼šä½¿ç”¨ freezegun å›ºå®šæ—¶é—´
from freezegun import freeze_time

@freeze_time("2023-01-01 12:00:00")
def test_time_dependent_function():
    result = get_current_time_info()
    assert result["hour"] == 12
```